{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext 6li",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPzlcxm2zc1PizLbaq3lQr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuyguA/computational_linguistics/blob/master/fasttext_6li.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sXqx9ZC4JO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c9b86578-386f-452a-c5ff-6c9837aa49bc"
      },
      "source": [
        "!!pip3 install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting fasttext',\n",
              " '\\x1b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)',\n",
              " '',\n",
              " '\\x1b[K     |████▊                           | 10kB 20.0MB/s eta 0:00:01',\n",
              " '\\x1b[K     |█████████▌                      | 20kB 1.8MB/s eta 0:00:01',\n",
              " '\\x1b[K     |██████████████▎                 | 30kB 2.6MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████             | 40kB 1.7MB/s eta 0:00:01',\n",
              " '\\x1b[K     |███████████████████████▉        | 51kB 2.1MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████▋   | 61kB 2.5MB/s eta 0:00:01',\n",
              " '\\x1b[K     |████████████████████████████████| 71kB 2.2MB/s ',\n",
              " '\\x1b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)',\n",
              " 'Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.3)',\n",
              " 'Building wheels for collected packages: fasttext',\n",
              " '  Building wheel for fasttext (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3016272 sha256=2899f19d9a382bd8df1b68c0dc17fe283cd2ff7668e4fa98a6c4af6ddab302eb',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592',\n",
              " 'Successfully built fasttext',\n",
              " 'Installing collected packages: fasttext',\n",
              " 'Successfully installed fasttext-0.9.2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzobhMIbDCel"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlOrTTPNDOJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "59a9fd52-8f06-44d4-f3ec-0172bbdb4a0f"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-03 16:09:24--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4506977940 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.tr.300.bin.gz’\n",
            "\n",
            "cc.tr.300.bin.gz    100%[===================>]   4.20G  23.2MB/s    in 3m 2s   \n",
            "\n",
            "2020-05-03 16:12:26 (23.7 MB/s) - ‘cc.tr.300.bin.gz’ saved [4506977940/4506977940]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNN_hKGkDavB"
      },
      "source": [
        "!gzip -d cc.tr.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ynYKIM2DbIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a98d0471-8a47-4f34-f884-076456041ffa"
      },
      "source": [
        "m = fasttext.load_model(\"cc.tr.300.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXbX2sPCDbZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a01ee69-39e0-47ad-aabc-3542af94807f"
      },
      "source": [
        "dir(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_labels',\n",
              " '_words',\n",
              " 'f',\n",
              " 'get_analogies',\n",
              " 'get_dimension',\n",
              " 'get_input_matrix',\n",
              " 'get_input_vector',\n",
              " 'get_label_id',\n",
              " 'get_labels',\n",
              " 'get_line',\n",
              " 'get_meter',\n",
              " 'get_nearest_neighbors',\n",
              " 'get_output_matrix',\n",
              " 'get_sentence_vector',\n",
              " 'get_subword_id',\n",
              " 'get_subwords',\n",
              " 'get_word_id',\n",
              " 'get_word_vector',\n",
              " 'get_words',\n",
              " 'is_quantized',\n",
              " 'labels',\n",
              " 'predict',\n",
              " 'quantize',\n",
              " 'save_model',\n",
              " 'set_args',\n",
              " 'set_matrices',\n",
              " 'test',\n",
              " 'test_label',\n",
              " 'words']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEm98caKDbpf"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7B3xFoQrwyg"
      },
      "source": [
        "import re\n",
        "\n",
        "#from emoticon_smiley import replace_smileys\n",
        "\n",
        "opponents = [\"bimcell\", \"pttcell\", \"ttnet\", \"vodafone\", \"avea\", \"netcell\", \"vestelcell\", \"turk telekom\", \"turktelekom\", \"turknet\"]\n",
        "opp_regex = r\"@?(\" + r\"|\".join(opponents) + r\")(\\w+)?\"\n",
        "\n",
        "\n",
        "def replace_opponents(sentence):\n",
        "  sentence = re.sub(opp_regex, \" rakip şirket \", sentence, flags=re.I)\n",
        "  return sentence\n",
        "\n",
        "def replace_self_mentions(sentence):\n",
        "  sentence = re.sub(\"t.?rkcll?\", \"turkcell\", sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_entities(sentence):\n",
        "  #sentence = replace_ceo(sentence)\n",
        "  sentence = replace_opponents(sentence)\n",
        "  sentence = replace_self_mentions(sentence)\n",
        "  return sentence\n",
        "\n",
        "def replace_dots(sentence):\n",
        "  sentence = sentence.replace(u\"\\u2026\", \"...\").replace(u\"\\u2025\", \"..\").replace(u\"\\u1427\", \".\")\n",
        "  return sentence\n",
        "\n",
        "def replace_brackets(sentence):\n",
        "  sentence = sentence.replace(\"}\", \" \").replace(\"{\", \" \").replace(\"]\", \" \").replace(\"[\", \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_quotation_marks(sentence):\n",
        "  rlist = [ u\"\\u2018\", u\"\\u201c\", u\"\\u201d\", '\"', u\"\\u0060\", u\"\\u00b4\", u\"\\u2019\"]\n",
        "  for r in rlist:\n",
        "    sentence = sentence.replace(r, \" \")\n",
        "  return sentence\n",
        "\n",
        "def replace_url(sentence):\n",
        "  url_string = r\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\"\n",
        "  return re.sub(url_string, \" websitesi \", sentence)\n",
        "\n",
        "def process_quotation(sentence):\n",
        "  sentence = re.sub(r\"(?<![.\\d])\\.\", \" .\", sentence)\n",
        "  sentence = re.sub(r\"\\.(?![.\\d])\", \". \", sentence)\n",
        "  sentence = re.sub(r\"(?<=\\w)([,:;])\", r\" \\1\", sentence)\n",
        "  sentence = sentence.replace(\"?\", \" ? \").replace(\"!\", \" ! \")\n",
        "  sentence = re.sub(r\"[\\s#\\@_<>|-]\", \" \", sentence)\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.strip()\n",
        "  sentence = sentence.lower()\n",
        "  sentence = replace_entities(sentence)\n",
        "  sentence = replace_dots(sentence)\n",
        "  sentence = replace_brackets(sentence)\n",
        "  sentence = replace_quotation_marks(sentence)\n",
        "  sentence = process_quotation(sentence)\n",
        "  tokens = sentence.strip().split()\n",
        "  #t = replace_smileys(tokens)\n",
        "  return  tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyi7XqSXsbc1"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxRcCjH6sbvA",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "ff69ec3d-f25e-42e6-e5bb-6ae2e567f9a2"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f3cb42d-ad3c-4d9a-b6d2-e76f0663c768\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2f3cb42d-ad3c-4d9a-b6d2-e76f0663c768\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving alls.csv to alls.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0sc7dmQscCz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0I6B33ls-VY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZneeHtncUa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UYyffRNs-nm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5rK794ki4W0"
      },
      "source": [
        "data = pd.read_excel('sentiment_labeled_data.xlsx', converters={\"OTHER\":int})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtlW6_AjgDDT"
      },
      "source": [
        "supplement = pd.read_csv('supplement.csv', encoding='utf8', sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iXq0Bf7gmFG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1a94a912-7d8d-4344-979d-2fd0d844801d"
      },
      "source": [
        "supplement.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORJINAL</th>\n",
              "      <th>SORU</th>\n",
              "      <th>PROBLEM</th>\n",
              "      <th>TALEP</th>\n",
              "      <th>ANAHTAR</th>\n",
              "      <th>EMİR</th>\n",
              "      <th>OTHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>internetim yok</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>su an internetim yok</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>su an internetim yok yine</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>şu an internetim yok yine</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>şu an internet yok</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     ORJINAL  SORU  PROBLEM  TALEP  ANAHTAR  EMİR  OTHER\n",
              "0             internetim yok     0        1      0        0     0      0\n",
              "1       su an internetim yok     0        1      0        0     0      0\n",
              "2  su an internetim yok yine     0        1      0        0     0      0\n",
              "3  şu an internetim yok yine     0        1      0        0     0      0\n",
              "4         şu an internet yok     0        1      0        0     0      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMutdd-ToNVR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31a341cf-7943-4431-bd8b-ea42cd825856"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu_WAXEbfLWO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQaVHn9s-8b"
      },
      "source": [
        "sentences = []\n",
        "y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dARL26YSoZDo"
      },
      "source": [
        "for index, row in data.iterrows():\n",
        "    sentences.append(row[\"ORJINAL\"])\n",
        "    y.append([row[\"SORU\"], row[\"PROBLEM\"], row[\"TALEP\"], row[\"ANAHTAR\"], row[\"EMİR\"], row[\"OTHER\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geQLwoMcgYZC"
      },
      "source": [
        "for index, row in supplement.iterrows():\n",
        "    sentences.append(row[\"ORJINAL\"])\n",
        "    y.append([row[\"SORU\"], row[\"PROBLEM\"], row[\"TALEP\"], row[\"ANAHTAR\"], row[\"EMİR\"], row[\"OTHER\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIvDF6fcrxW-"
      },
      "source": [
        "sequences = [preprocess(sentence) for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7wTofK0VesF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW9ARwGqJS5k"
      },
      "source": [
        "words = set()\n",
        "for sentence in sequences:\n",
        "    for word in sentence:\n",
        "        words.add(word)\n",
        "n_words = len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FNCtB7xggr"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "sequences, y = shuffle(sequences,  y, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc0cJMg6tvc9"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbKDaWOuuMb"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOatna3ZuugK"
      },
      "source": [
        "tok = Tokenizer(n_words+1, lower=True)\n",
        "tok.fit_on_texts(sequences)\n",
        "X_word = tok.texts_to_sequences(sequences)\n",
        "X_word = pad_sequences(X_word, maxlen=MAX_LEN, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Yuza8svgDD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fva_c95vv7TM"
      },
      "source": [
        "MAX_LEN =120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkFLUb_9wAfZ"
      },
      "source": [
        "word_index = tok.word_index\n",
        "embed_size=300\n",
        "embedding_matrix = np.zeros((n_words+1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= n_words: continue\n",
        "    embedding_vector = m.get_word_vector(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIoRIdyMxZcp"
      },
      "source": [
        "X_word = np.array(X_word)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rALlHlRiwwRS"
      },
      "source": [
        "word_in = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(100, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=word_in, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1_LsHzTyCbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "441d234c-201d-4fff-d56f-b32431e75863"
      },
      "source": [
        "history = model.fit(X_word, y, batch_size=64, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1088/5089 [=====>........................] - ETA: 25s - loss: 0.5444 - accuracy: 0.8044"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-227-11ff5113d4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2mEb83_z-x_"
      },
      "source": [
        "examples = [ \n",
        "    \"yardimci olabilirmisiniz\",\n",
        "    \"nasil internet kazanabilirim yardimci olabilir misiniz\",\n",
        "    \"nasil internet kazanabilirim\",\n",
        "    \"faturam ne kadar simdi\",\n",
        "    \"internet kazanmanin baska yollari var mi acaba\",\n",
        "    \"yetkiliyle gorusmek istiyorum\",\n",
        "    \"yetkiliyle görüşmek istyrm\",\n",
        "    \"internetim çalışmıyor\",\n",
        "    \"kontor yükleyemedim\",\n",
        "    \"evimde internet baglantisi yok\",\n",
        "    \"kontör yükleyemedim yardımcı olur musunuz\",\n",
        "    \"sen de kimsin\",\n",
        "    \"selam\",\n",
        "    \"selam merhaba\",\n",
        "    \"merhabalar\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie8eQolm7Hpf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8zCbXMi6kgK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebsKqiBA6k8L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baf69b9f-d0c5-493c-a460-54ee2489ea26"
      },
      "source": [
        "for ex in examples:\n",
        "    tt = tok.texts_to_sequences([ex])\n",
        "    ptt = pad_sequences(tt, MAX_LEN, padding=\"post\")\n",
        "    pred = model.predict(ptt)\n",
        "    print(ex)\n",
        "    show_pred(pred[0])\n",
        "    print(\"---------------\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yardimci olabilirmisiniz\n",
            "Prediction: SORU (0.928) | ANAHTAR (0.0151) | PROBLEM (0.0119) | EMIR (0.0111) | TALEP (0.00386) | OTHER (0.00228)\n",
            "---------------\n",
            "\n",
            "\n",
            "nasil internet kazanabilirim yardimci olabilir misiniz\n",
            "Prediction: SORU (1.0) | PROBLEM (0.00505) | TALEP (0.00454) | ANAHTAR (0.000171) | EMIR (7.3e-05) | OTHER (4.05e-06)\n",
            "---------------\n",
            "\n",
            "\n",
            "nasil internet kazanabilirim\n",
            "Prediction: SORU (1.0) | ANAHTAR (0.00601) | PROBLEM (0.00127) | EMIR (0.000684) | TALEP (0.000217) | OTHER (0.000208)\n",
            "---------------\n",
            "\n",
            "\n",
            "faturam ne kadar simdi\n",
            "Prediction: SORU (1.0) | ANAHTAR (0.00888) | EMIR (0.000788) | OTHER (0.000747) | PROBLEM (0.000569) | TALEP (3.98e-05)\n",
            "---------------\n",
            "\n",
            "\n",
            "internet kazanmanin baska yollari var mi acaba\n",
            "Prediction: SORU (1.0) | PROBLEM (0.00258) | ANAHTAR (0.000361) | EMIR (4.26e-05) | OTHER (4.14e-05) | TALEP (2.31e-05)\n",
            "---------------\n",
            "\n",
            "\n",
            "yetkiliyle gorusmek istiyorum\n",
            "Prediction: TALEP (0.992) | EMIR (0.0151) | ANAHTAR (0.00633) | PROBLEM (0.00216) | SORU (0.0012) | OTHER (0.00087)\n",
            "---------------\n",
            "\n",
            "\n",
            "yetkiliyle görüşmek istyrm\n",
            "Prediction: TALEP (0.977) | EMIR (0.0541) | ANAHTAR (0.0139) | PROBLEM (0.00423) | OTHER (0.00271) | SORU (0.00172)\n",
            "---------------\n",
            "\n",
            "\n",
            "internetim çalışmıyor\n",
            "Prediction: PROBLEM (0.988) | OTHER (0.0165) | SORU (0.0147) | EMIR (0.00284) | TALEP (0.000504) | ANAHTAR (0.000314)\n",
            "---------------\n",
            "\n",
            "\n",
            "kontor yükleyemedim\n",
            "Prediction: PROBLEM (0.98) | OTHER (0.0816) | EMIR (0.00389) | TALEP (0.00224) | ANAHTAR (0.000381) | SORU (0.000332)\n",
            "---------------\n",
            "\n",
            "\n",
            "evimde internet baglantisi yok\n",
            "Prediction: PROBLEM (0.649) | OTHER (0.343) | EMIR (0.00343) | SORU (0.00205) | ANAHTAR (0.00172) | TALEP (0.00122)\n",
            "---------------\n",
            "\n",
            "\n",
            "kontör yükleyemedim yardımcı olur musunuz\n",
            "Prediction: PROBLEM (0.999) | SORU (0.0146) | TALEP (0.00163) | EMIR (0.00123) | OTHER (0.000812) | ANAHTAR (2.49e-05)\n",
            "---------------\n",
            "\n",
            "\n",
            "sen de kimsin\n",
            "Prediction: ANAHTAR (0.425) | OTHER (0.317) | EMIR (0.147) | SORU (0.108) | PROBLEM (0.00159) | TALEP (0.00128)\n",
            "---------------\n",
            "\n",
            "\n",
            "selam\n",
            "Prediction: OTHER (0.898) | ANAHTAR (0.248) | EMIR (0.0699) | PROBLEM (0.00678) | TALEP (0.00357) | SORU (0.00258)\n",
            "---------------\n",
            "\n",
            "\n",
            "selam merhaba\n",
            "Prediction: OTHER (0.968) | ANAHTAR (0.0797) | EMIR (0.0164) | PROBLEM (0.00822) | TALEP (0.00147) | SORU (0.00137)\n",
            "---------------\n",
            "\n",
            "\n",
            "merhabalar\n",
            "Prediction: OTHER (0.959) | PROBLEM (0.0318) | ANAHTAR (0.0252) | EMIR (0.00861) | SORU (0.00154) | TALEP (0.000665)\n",
            "---------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Csk-Rf6qez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c065c4d3-cd60-4562-9283-641bbc965488"
      },
      "source": [
        "results = model.evaluate(X_test, testy, batch_size=32)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "689/689 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5893192580415826, 0.8248669505119324]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19BCFAu7HnD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZniIhvkP8KHu"
      },
      "source": [
        "label_dict = {0: \"SORU\", 1: \"PROBLEM\", 2:\"TALEP\", 3:\"ANAHTAR\", 4:\"EMIR\", 5:\"OTHER\"}\n",
        "\n",
        "def show_pred(pred):\n",
        "    print(\"Prediction: {}\".format(\" | \".join([\"{} ({:.3})\".format(label_dict[s],\n",
        "                                                                pred[s])\n",
        "                                            for s in pred.argsort()[::-1]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK3GAGuk9BJm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB82A27u9IA6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uEO0i29RGf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Ge8TKs1EPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaf4d5ff-10c3-4737-d2e9-dabf6aeb5eb4"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "weight_decay = 1e-4\n",
        "num_filters=64\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(n_words+1, embed_size, embeddings_initializer=Constant(embedding_matrix), input_length=MAX_LEN, trainable=True)(word_in)\n",
        "conv = Conv1D(num_filters, 7, activation='relu', padding='same')(x)\n",
        "mp1 = MaxPooling1D(2)(conv)\n",
        "conv1 = Conv1D(num_filters, 7, activation='relu', padding='same')(mp1)\n",
        "mp2 = GlobalMaxPooling1D()(conv1)\n",
        "dp1 = Dropout(0.5)(mp2)\n",
        "dense1  = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(dp1)\n",
        "dense2 = Dense(6, activation='sigmoid')(dense1)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model2 = Model(input=word_in, outputs=dense2)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UFJi89o1Lgn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "9773efb6-d3b4-4b62-af1e-dcd5f701f303"
      },
      "source": [
        "model2.fit(X_word,y, batch_size=32, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0449 - accuracy: 0.9891\n",
            "Epoch 2/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0261 - accuracy: 0.9933\n",
            "Epoch 3/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0231 - accuracy: 0.9942\n",
            "Epoch 4/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0201 - accuracy: 0.9949\n",
            "Epoch 5/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0176 - accuracy: 0.9958\n",
            "Epoch 6/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0154 - accuracy: 0.9962\n",
            "Epoch 7/10\n",
            "5089/5089 [==============================] - 12s 2ms/step - loss: 0.0160 - accuracy: 0.9953\n",
            "Epoch 8/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0143 - accuracy: 0.9959\n",
            "Epoch 9/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0146 - accuracy: 0.9961\n",
            "Epoch 10/10\n",
            "5089/5089 [==============================] - 11s 2ms/step - loss: 0.0142 - accuracy: 0.9963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fb254863278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjeuqgVLLXDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5953f531-b24e-44eb-f188-d5ff9dd3d59d"
      },
      "source": [
        "for ex in examples:\n",
        "    tt = tok.texts_to_sequences([ex])\n",
        "    ptt = pad_sequences(tt, MAX_LEN, padding=\"post\")\n",
        "    pred = model2.predict(ptt)\n",
        "    print(ex)\n",
        "    show_pred(pred[0])\n",
        "    print(\"---------------\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yardimci olabilirmisiniz\n",
            "Prediction: SORU (0.998) | PROBLEM (0.0289) | ANAHTAR (0.0197) | TALEP (0.00768) | OTHER (0.00047) | EMIR (4.19e-06)\n",
            "---------------\n",
            "\n",
            "\n",
            "nasil internet kazanabilirim yardimci olabilir misiniz\n",
            "Prediction: SORU (1.0) | TALEP (9.5e-05) | PROBLEM (5.2e-06) | ANAHTAR (1.88e-06) | OTHER (2.25e-09) | EMIR (7.15e-16)\n",
            "---------------\n",
            "\n",
            "\n",
            "nasil internet kazanabilirim\n",
            "Prediction: SORU (1.0) | TALEP (3.47e-05) | ANAHTAR (2.71e-05) | PROBLEM (4.54e-06) | OTHER (1.28e-07) | EMIR (7.26e-14)\n",
            "---------------\n",
            "\n",
            "\n",
            "faturam ne kadar simdi\n",
            "Prediction: SORU (1.0) | ANAHTAR (4.86e-06) | TALEP (4.8e-06) | PROBLEM (8.15e-07) | OTHER (2.99e-08) | EMIR (9.34e-16)\n",
            "---------------\n",
            "\n",
            "\n",
            "internet kazanmanin baska yollari var mi acaba\n",
            "Prediction: SORU (1.0) | ANAHTAR (5.8e-05) | TALEP (3.82e-05) | PROBLEM (2.56e-05) | OTHER (1.61e-07) | EMIR (1.27e-13)\n",
            "---------------\n",
            "\n",
            "\n",
            "yetkiliyle gorusmek istiyorum\n",
            "Prediction: TALEP (0.965) | OTHER (0.0345) | EMIR (0.0126) | SORU (0.00401) | ANAHTAR (0.000189) | PROBLEM (9.78e-05)\n",
            "---------------\n",
            "\n",
            "\n",
            "yetkiliyle görüşmek istyrm\n",
            "Prediction: TALEP (0.9) | OTHER (0.125) | EMIR (0.0253) | SORU (0.00741) | ANAHTAR (0.00107) | PROBLEM (0.000456)\n",
            "---------------\n",
            "\n",
            "\n",
            "internetim çalışmıyor\n",
            "Prediction: PROBLEM (0.999) | SORU (0.258) | ANAHTAR (0.00298) | TALEP (0.000226) | OTHER (0.000188) | EMIR (9.58e-05)\n",
            "---------------\n",
            "\n",
            "\n",
            "kontor yükleyemedim\n",
            "Prediction: PROBLEM (1.0) | OTHER (7.34e-05) | EMIR (1.62e-05) | SORU (9.35e-06) | ANAHTAR (1.32e-06) | TALEP (3.81e-07)\n",
            "---------------\n",
            "\n",
            "\n",
            "evimde internet baglantisi yok\n",
            "Prediction: PROBLEM (0.976) | OTHER (0.127) | EMIR (0.00236) | ANAHTAR (0.00158) | SORU (0.000749) | TALEP (0.000421)\n",
            "---------------\n",
            "\n",
            "\n",
            "kontör yükleyemedim yardımcı olur musunuz\n",
            "Prediction: PROBLEM (1.0) | SORU (0.000203) | OTHER (3.63e-06) | EMIR (3.24e-06) | ANAHTAR (9.03e-07) | TALEP (6.18e-07)\n",
            "---------------\n",
            "\n",
            "\n",
            "sen de kimsin\n",
            "Prediction: OTHER (0.953) | ANAHTAR (0.0876) | SORU (0.00786) | TALEP (0.000699) | PROBLEM (0.000567) | EMIR (0.000437)\n",
            "---------------\n",
            "\n",
            "\n",
            "selam\n",
            "Prediction: OTHER (0.964) | ANAHTAR (0.0455) | PROBLEM (0.00482) | EMIR (0.00214) | SORU (0.00156) | TALEP (0.00147)\n",
            "---------------\n",
            "\n",
            "\n",
            "selam merhaba\n",
            "Prediction: OTHER (1.0) | ANAHTAR (0.000314) | PROBLEM (0.00014) | TALEP (1.96e-05) | EMIR (1.03e-05) | SORU (5e-06)\n",
            "---------------\n",
            "\n",
            "\n",
            "merhabalar\n",
            "Prediction: OTHER (0.992) | ANAHTAR (0.00813) | PROBLEM (0.00305) | EMIR (0.000244) | SORU (0.000187) | TALEP (0.000178)\n",
            "---------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpaC0t9667fC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g43lxLQq675l"
      },
      "source": [
        "model2.save(\"sixclass_model.hd5\")\n",
        "\n",
        "import json, codecs\n",
        "\n",
        "#tokenizer_json = tok.to_json()\n",
        "#with codecs.open('sixclass_tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "#    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnw7TZR_J32"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPMH7GWtnYPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaPX6JyS_YVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPTUPxY4t2b2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FRcZw3RAed5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
